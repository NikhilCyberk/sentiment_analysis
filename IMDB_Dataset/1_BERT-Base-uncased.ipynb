{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch transformers tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def verify_cuda_setup():\n",
    "#     \"\"\"\n",
    "#     Verify CUDA setup and provide detailed information\n",
    "#     \"\"\"\n",
    "#     print(\"\\n=== CUDA Setup Verification ===\")\n",
    "    \n",
    "#     # Check PyTorch installation\n",
    "#     print(f\"PyTorch Version: {torch.__version__}\")\n",
    "#     print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "#     if torch.cuda.is_available():\n",
    "#         # Get CUDA version\n",
    "#         cuda_version = torch.version.cuda\n",
    "#         print(f\"CUDA Version: {cuda_version}\")\n",
    "        \n",
    "#         # GPU Device information\n",
    "#         current_device = torch.cuda.current_device()\n",
    "#         print(f\"Current CUDA device index: {current_device}\")\n",
    "#         print(f\"GPU Device: {torch.cuda.get_device_name(current_device)}\")\n",
    "        \n",
    "#         # Memory information\n",
    "#         print(\"\\nGPU Memory Information:\")\n",
    "#         print(f\"Total GPU Memory: {torch.cuda.get_device_properties(current_device).total_memory / 1024**3:.2f} GB\")\n",
    "#         print(f\"Memory Allocated: {torch.cuda.memory_allocated(current_device) / 1024**3:.2f} GB\")\n",
    "#         print(f\"Memory Cached: {torch.cuda.memory_reserved(current_device) / 1024**3:.2f} GB\")\n",
    "        \n",
    "#         # CUDA architecture\n",
    "#         print(f\"\\nCUDA Architecture:\")\n",
    "#         print(f\"Device Capability: {torch.cuda.get_device_capability(current_device)}\")\n",
    "        \n",
    "#         # Test CUDA computation\n",
    "#         print(\"\\nTesting CUDA computation...\")\n",
    "#         try:\n",
    "#             test_tensor = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
    "#             result = test_tensor.sum()\n",
    "#             print(\"CUDA computation test: Successful\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"CUDA computation test failed: {e}\")\n",
    "            \n",
    "#         return torch.device('cuda')\n",
    "#     else:\n",
    "#         print(\"\\nWARNING: CUDA is not available. Check your PyTorch installation and NVIDIA drivers.\")\n",
    "#         print(\"\\nDebug Information:\")\n",
    "#         print(f\"PyTorch CUDA arch list: {os.environ.get('TORCH_CUDA_ARCH_LIST', 'Not Set')}\")\n",
    "#         print(f\"CUDA_HOME: {os.environ.get('CUDA_HOME', 'Not Set')}\")\n",
    "#         print(f\"CUDA_PATH: {os.environ.get('CUDA_PATH', 'Not Set')}\")\n",
    "#         return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cuda_setup():\n",
    "    \"\"\"\n",
    "    Verify CUDA setup and provide detailed information\n",
    "    \"\"\"\n",
    "    print(\"\\n=== CUDA Setup Verification ===\")\n",
    "    \n",
    "    # Check PyTorch installation\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        # Get CUDA version\n",
    "        cuda_version = torch.version.cuda\n",
    "        print(f\"CUDA Version: {cuda_version}\")\n",
    "        \n",
    "        # GPU Device information\n",
    "        current_device = torch.cuda.current_device()\n",
    "        print(f\"Current CUDA device index: {current_device}\")\n",
    "        print(f\"GPU Device: {torch.cuda.get_device_name(current_device)}\")\n",
    "        \n",
    "        # Memory information\n",
    "        print(\"\\nGPU Memory Information:\")\n",
    "        print(f\"Total GPU Memory: {torch.cuda.get_device_properties(current_device).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"Memory Allocated: {torch.cuda.memory_allocated(current_device) / 1024**3:.2f} GB\")\n",
    "        print(f\"Memory Cached: {torch.cuda.memory_reserved(current_device) / 1024**3:.2f} GB\")\n",
    "        \n",
    "        # CUDA architecture\n",
    "        print(f\"\\nCUDA Architecture:\")\n",
    "        print(f\"Device Capability: {torch.cuda.get_device_capability(current_device)}\")\n",
    "        \n",
    "        # Test CUDA computation\n",
    "        print(\"\\nTesting CUDA computation...\")\n",
    "        try:\n",
    "            test_tensor = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
    "            result = test_tensor.sum()\n",
    "            print(\"CUDA computation test: Successful\")\n",
    "        except Exception as e:\n",
    "            print(f\"CUDA computation test failed: {e}\")\n",
    "            \n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        print(\"\\nWARNING: CUDA is not available. Check your PyTorch installation and NVIDIA drivers.\")\n",
    "        print(\"\\nDebug Information:\")\n",
    "        print(f\"PyTorch CUDA arch list: {os.environ.get('TORCH_CUDA_ARCH_LIST', 'Not Set')}\")\n",
    "        print(f\"CUDA_HOME: {os.environ.get('CUDA_HOME', 'Not Set')}\")\n",
    "        print(f\"CUDA_PATH: {os.environ.get('CUDA_PATH', 'Not Set')}\")\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CUDA Setup Verification ===\n",
      "PyTorch Version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA Version: 12.1\n",
      "Current CUDA device index: 0\n",
      "GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "\n",
      "GPU Memory Information:\n",
      "Total GPU Memory: 4.00 GB\n",
      "Memory Allocated: 0.00 GB\n",
      "Memory Cached: 0.00 GB\n",
      "\n",
      "CUDA Architecture:\n",
      "Device Capability: (8, 6)\n",
      "\n",
      "Testing CUDA computation...\n",
      "CUDA computation test: Successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_cuda_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess the Twitter dataset\"\"\"\n",
    "    # column_names = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "    data = pd.read_csv(\"IMDB_Dataset.csv\", encoding='ISO-8859-1')\n",
    "    # data['target'] = data['category'].replace(-1, 2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_and_preprocess_data()\n",
    "# data = data.sample(n=30000, random_state=42)\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_47484\\3214355603.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['target'] = data['sentiment'].replace('positive', 1).replace('negative', 0)\n"
     ]
    }
   ],
   "source": [
    "data['target'] = data['sentiment'].replace('positive', 1).replace('negative', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "target       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    25000\n",
       "0    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of target col\n",
    "\n",
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  target\n",
       "0  One of the other reviewers has mentioned that ...  positive       1\n",
       "1  A wonderful little production. <br /><br />The...  positive       1\n",
       "2  I thought this was a wonderful way to spend ti...  positive       1\n",
       "3  Basically there's a family where a little boy ...  negative       0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_text_preprocessing(content):\n",
    "    # Check if content is a string, if not convert to string or return empty string\n",
    "    if not isinstance(content, str):\n",
    "        try:\n",
    "            content = str(content)\n",
    "        except:\n",
    "            return ''\n",
    "\n",
    "    # Initialize lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Convert to lowercase and remove special characters\n",
    "    lemmatized_content = re.sub(r'http\\S+|www\\S+|https\\S+', '', content, flags=re.MULTILINE)  # Remove URLs\n",
    "    lemmatized_content = re.sub(r'@\\w+|\\#', '', lemmatized_content)  # Remove mentions and hashtag symbols\n",
    "    lemmatized_content = re.sub(r'[^a-zA-Z\\s]', '', lemmatized_content)  # Remove numbers and punctuation\n",
    "    lemmatized_content = lemmatized_content.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    words = word_tokenize(lemmatized_content)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Add custom stopwords that might not be useful for sentiment\n",
    "    custom_stopwords = {'rt', 'via'}\n",
    "    stop_words.update(custom_stopwords)\n",
    "    processed_words = [\n",
    "        lemmatizer.lemmatize(word) for word in words if word not in stop_words and len(word) > 2\n",
    "    ]\n",
    "    lemmatized_content = ' '.join(processed_words)\n",
    "    return lemmatized_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying text preprocessing...\n"
     ]
    }
   ],
   "source": [
    " # Apply advanced text preprocessing\n",
    "    \n",
    "print(\"Applying text preprocessing...\")\n",
    "    \n",
    "data['lemmatized_content'] = data['review'].apply(advanced_text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>target</th>\n",
       "      <th>lemmatized_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer mentioned watching episode youll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  target  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive       1   \n",
       "1  A wonderful little production. <br /><br />The...  positive       1   \n",
       "2  I thought this was a wonderful way to spend ti...  positive       1   \n",
       "3  Basically there's a family where a little boy ...  negative       0   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive       1   \n",
       "\n",
       "                                  lemmatized_content  \n",
       "0  one reviewer mentioned watching episode youll ...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically there family little boy jake think t...  \n",
       "4  petter matteis love time money visually stunni...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0\n",
      "Empty DataFrame\n",
      "Columns: [review, sentiment, target, lemmatized_content]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for non-string values\n",
    "print(data['lemmatized_content'].dtype)\n",
    "print(data['lemmatized_content'].isnull().sum())\n",
    "print(data[data['lemmatized_content'].apply(lambda x: not isinstance(x, str))].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_bert_model(data, epochs=3, batch_size=32, learning_rate=2e-5):\n",
    "#     \"\"\"\n",
    "#     Train a BERT model for sentiment analysis\n",
    "    \n",
    "#     Parameters:\n",
    "#     data: pandas DataFrame with 'lemmatized_content' and 'target' columns\n",
    "#     epochs: number of training epochs\n",
    "#     batch_size: batch size for training\n",
    "#     learning_rate: learning rate for optimization\n",
    "#     \"\"\"\n",
    "#     # Set device\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "\n",
    "#     # Initialize tokenizer and model\n",
    "#     tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#     model = BertForSequenceClassification.from_pretrained(\n",
    "#         'bert-base-uncased',\n",
    "#         num_labels=2\n",
    "#     ).to(device)\n",
    "\n",
    "#     # Prepare data\n",
    "#     X = data['lemmatized_content'].values\n",
    "#     y = data['target'].values\n",
    "    \n",
    "#     X_train, X_val, y_train, y_val = train_test_split(\n",
    "#         X, y, test_size=0.2, stratify=y, random_state=42\n",
    "#     )\n",
    "\n",
    "#     # Create datasets\n",
    "#     train_dataset = TwitterDataset(X_train, y_train, tokenizer)\n",
    "#     val_dataset = TwitterDataset(X_val, y_val, tokenizer)\n",
    "\n",
    "#     # Create data loaders\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "#     # Initialize optimizer\n",
    "#     optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # Training loop\n",
    "#     best_accuracy = 0\n",
    "#     for epoch in range(epochs):\n",
    "#         print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "        \n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         train_losses = []\n",
    "#         train_preds = []\n",
    "#         train_true = []\n",
    "\n",
    "#         for batch in tqdm(train_loader, desc='Training'):\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             targets = batch['targets'].to(device)\n",
    "\n",
    "#             outputs = model(\n",
    "#                 input_ids=input_ids,\n",
    "#                 attention_mask=attention_mask,\n",
    "#                 labels=targets\n",
    "#             )\n",
    "\n",
    "#             loss = outputs.loss\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             train_losses.append(loss.item())\n",
    "            \n",
    "#             preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "#             train_preds.extend(preds)\n",
    "#             train_true.extend(targets.cpu().numpy())\n",
    "\n",
    "#         train_accuracy = accuracy_score(train_true, train_preds)\n",
    "        \n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_losses = []\n",
    "#         val_preds = []\n",
    "#         val_true = []\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in tqdm(val_loader, desc='Validation'):\n",
    "#                 input_ids = batch['input_ids'].to(device)\n",
    "#                 attention_mask = batch['attention_mask'].to(device)\n",
    "#                 targets = batch['targets'].to(device)\n",
    "\n",
    "#                 outputs = model(\n",
    "#                     input_ids=input_ids,\n",
    "#                     attention_mask=attention_mask,\n",
    "#                     labels=targets\n",
    "#                 )\n",
    "\n",
    "#                 val_losses.append(outputs.loss.item())\n",
    "                \n",
    "#                 preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "#                 val_preds.extend(preds)\n",
    "#                 val_true.extend(targets.cpu().numpy())\n",
    "\n",
    "#         val_accuracy = accuracy_score(val_true, val_preds)\n",
    "        \n",
    "#         print(f'\\nTraining Loss: {np.mean(train_losses):.4f}')\n",
    "#         print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "#         print(f'Validation Loss: {np.mean(val_losses):.4f}')\n",
    "#         print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "#         if val_accuracy > best_accuracy:\n",
    "#             best_accuracy = val_accuracy\n",
    "#             print(\"\\nSaving best model...\")\n",
    "#             torch.save(model.state_dict(), 'best_bert_model.pt')\n",
    "            \n",
    "#         print('\\nClassification Report:')\n",
    "#         print(classification_report(val_true, val_preds))\n",
    "\n",
    "#     return model, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_bert_model(data, epochs=3, batch_size=32, learning_rate=2e-5):\n",
    "    \"\"\"\n",
    "    Train a BERT model for sentiment analysis with improved error handling\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=2\n",
    "    ).to(device)\n",
    "\n",
    "    # Prepare data\n",
    "    X = data['lemmatized_content'].values\n",
    "    y = data['target'].values\n",
    "    \n",
    "    # Ensure target values are binary (0 or 1)\n",
    "    y = np.where(y > 1, 1, y)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = TwitterDataset(X_train, y_train, tokenizer)\n",
    "    val_dataset = TwitterDataset(X_val, y_val, tokenizer)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Initialize optimizer with weight decay\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "    # Training loop with mixed precision\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds = []\n",
    "        train_true = []\n",
    "\n",
    "        for batch in tqdm(train_loader, desc='Training'):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "\n",
    "            # Mixed precision training\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=targets\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "\n",
    "            # Scaled gradient\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            train_preds.extend(preds)\n",
    "            train_true.extend(targets.cpu().numpy())\n",
    "\n",
    "        train_accuracy = accuracy_score(train_true, train_preds)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc='Validation'):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                targets = batch['targets'].to(device)\n",
    "\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=targets\n",
    "                    )\n",
    "\n",
    "                val_losses.append(outputs.loss.item())\n",
    "                \n",
    "                preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_true.extend(targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_true, val_preds)\n",
    "        \n",
    "        print(f'\\nTraining Loss: {np.mean(train_losses):.4f}')\n",
    "        print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "        print(f'Validation Loss: {np.mean(val_losses):.4f}')\n",
    "        print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            print(\"\\nSaving best model...\")\n",
    "            torch.save(model.state_dict(), 'best_bert_model.pt')\n",
    "            \n",
    "        print('\\nClassification Report:')\n",
    "        print(classification_report(val_true, val_preds))\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, device=None):\n",
    "    \"\"\"\n",
    "    Predict sentiment for a single text input with CUDA optimization\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model.eval()\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if device.type == 'cuda':\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        else:\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    return \"Positive\" if prediction == 1 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    25000\n",
       "0    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of target col\n",
    "\n",
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    one reviewer mentioned watching episode youll ...\n",
      "1    wonderful little production filming technique ...\n",
      "2    thought wonderful way spend time hot summer we...\n",
      "3    basically there family little boy jake think t...\n",
      "4    petter matteis love time money visually stunni...\n",
      "Name: lemmatized_content, dtype: object\n",
      "[1 0]\n",
      "target\n",
      "1    25000\n",
      "0    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure data is clean and preprocessed correctly\n",
    "print(data['lemmatized_content'].head())\n",
    "print(data['target'].unique())\n",
    "print(data['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nikhi\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_47484\\2109533444.py:159: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1250 [00:00<?, ?it/s]C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_47484\\2109533444.py:179: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 1250/1250 [07:16<00:00,  2.87it/s]\n",
      "Validation:   0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_47484\\2109533444.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 313/313 [00:39<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.3212\n",
      "Training Accuracy: 0.8584\n",
      "Validation Loss: 0.2551\n",
      "Validation Accuracy: 0.8910\n",
      "\n",
      "Saving best model...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89      5000\n",
      "           1       0.87      0.92      0.89      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1250 [00:00<?, ?it/s]C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_47484\\2109533444.py:179: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 1250/1250 [07:16<00:00,  2.86it/s]\n",
      "Validation:   0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_47484\\2109533444.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 313/313 [00:39<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.1994\n",
      "Training Accuracy: 0.9223\n",
      "Validation Loss: 0.2521\n",
      "Validation Accuracy: 0.8971\n",
      "\n",
      "Saving best model...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      5000\n",
      "           1       0.91      0.88      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1250 [00:00<?, ?it/s]C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_47484\\2109533444.py:179: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 1250/1250 [07:16<00:00,  2.86it/s]\n",
      "Validation:   0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_47484\\2109533444.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 313/313 [00:39<00:00,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.1121\n",
      "Training Accuracy: 0.9592\n",
      "Validation Loss: 0.3180\n",
      "Validation Accuracy: 0.8948\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      5000\n",
      "           1       0.89      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = train_bert_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test text: This is a wonderful day! I'm really happy!\n",
      "Predicted sentiment: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_47484\\3602477452.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "test_text = \"This is a wonderful day! I'm really happy!\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
    "print(f\"\\nTest text: {test_text}\")\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Laptop GPU'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Model Performance Report\n",
    "\n",
    "## Model Overview\n",
    "- **Model Type**: BERT-based Sequence Classification\n",
    "- **Dataset**: IMDB Movie Reviews\n",
    "- **Preprocessing**: Advanced text preprocessing with lemmatization and stopword removal\n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Overall Accuracy** | 89.48% |\n",
    "| **Precision (Negative)** | 0.90 |\n",
    "| **Recall (Negative)** | 0.88 |\n",
    "| **F1-Score (Negative)** | 0.89 |\n",
    "| **Precision (Positive)** | 0.89 |\n",
    "| **Recall (Positive)** | 0.91 |\n",
    "| **F1-Score (Positive)** | 0.90 |\n",
    "\n",
    "## Training Progression\n",
    "\n",
    "| Epoch | Training Loss | Training Accuracy | Validation Loss | Validation Accuracy |\n",
    "|-------|--------------|-------------------|----------------|---------------------|\n",
    "| 1 | 0.3212 | 85.84% | 0.2551 | 89.10% |\n",
    "| 2 | 0.1994 | 92.23% | 0.2521 | 89.71% |\n",
    "| 3 | 0.1121 | 95.92% | 0.3180 | 89.48% |\n",
    "\n",
    "## Key Findings\n",
    "1. Consistent high performance across epochs\n",
    "2. Slight overfitting observed in later epochs\n",
    "3. Balanced performance between positive and negative sentiment classification\n",
    "\n",
    "## Model Configuration\n",
    "- **Tokenizer**: BERT Base Uncased\n",
    "- **Optimizer**: AdamW with weight decay\n",
    "- **Learning Rate**: 2e-5\n",
    "- **Batch Size**: 32\n",
    "- **Training Epochs**: 3\n",
    "\n",
    "## Preprocessing Techniques\n",
    "- Lemmatization\n",
    "- Stopword removal\n",
    "- URL and special character removal\n",
    "- Lowercasing\n",
    "\n",
    "## Challenges and Limitations\n",
    "- Potential domain-specific bias\n",
    "- Limited to binary sentiment classification\n",
    "- Performance may vary with different datasets\n",
    "\n",
    "## Recommendations\n",
    "1. Experiment with learning rate scheduling\n",
    "2. Try longer training with early stopping\n",
    "3. Explore domain-specific pre-training\n",
    "4. Implement cross-validation for robust evaluation\n",
    "\n",
    "## Conclusion\n",
    "The BERT-based sentiment analysis model demonstrates strong performance with 89.48% accuracy, showing effective sentiment classification capabilities across movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
