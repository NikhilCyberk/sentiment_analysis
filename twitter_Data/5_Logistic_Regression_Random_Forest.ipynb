{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess the Twitter dataset\"\"\"\n",
    "    # column_names = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "    data = pd.read_csv(\"Twitter_Data.csv\", encoding='ISO-8859-1')\n",
    "    data['target'] = data['category'].replace(-1, 2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162980, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample data 10,000 rows randomly\n",
    "data = load_and_preprocess_data()\n",
    "# data = data.sample(n=30000, random_state=42)\n",
    "\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised âminimum government maxim...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  target\n",
       "0  when modi promised âminimum government maxim...      -1.0     2.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0     0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0     1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0     1.0\n",
       "4  answer who among these the most powerful world...       1.0     1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \"\"\"Main function to run the improved sentiment analysis\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised âminimum government maxim...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  target\n",
       "0  when modi promised âminimum government maxim...      -1.0     2.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0     0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0     1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0     1.0\n",
       "4  answer who among these the most powerful world...       1.0     1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162980, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    0\n",
       "category      0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the num of missing values in the dataset\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1.0    72249\n",
       "0.0    55211\n",
       "2.0    35509\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of target col\n",
    "\n",
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_text_preprocessing(content):\n",
    "\n",
    "    # Initialize lemmatizer\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Convert to lowercase and remove special characters\n",
    "    lemmatized_content = re.sub(r'http\\S+|www\\S+|https\\S+', '', content, flags=re.MULTILINE)  # Remove URLs\n",
    "    lemmatized_content = re.sub(r'@\\w+|\\#', '', lemmatized_content)  # Remove mentions and hashtag symbols\n",
    "    lemmatized_content = re.sub(r'[^a-zA-Z\\s]', '', lemmatized_content)  # Remove numbers and punctuation\n",
    "    lemmatized_content = lemmatized_content.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    words = word_tokenize(lemmatized_content)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Add custom stopwords that might not be useful for sentiment\n",
    "    custom_stopwords = {'rt', 'via'}\n",
    "    stop_words.update(custom_stopwords)\n",
    "    processed_words = [\n",
    "        lemmatizer.lemmatize(word) for word in words if word not in stop_words and len(word) > 2\n",
    "    ]\n",
    "    lemmatized_content = ' '.join(processed_words)\n",
    "    return lemmatized_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    when modi promised âminimum government maxim...\n",
       "1    talk all the nonsense and continue all the dra...\n",
       "2    what did just say vote for modi  welcome bjp t...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data['clean_text'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying text preprocessing...\n"
     ]
    }
   ],
   "source": [
    " # Apply advanced text preprocessing\n",
    "    \n",
    "print(\"Applying text preprocessing...\")\n",
    "    \n",
    "data['lemmatized_content'] = data['clean_text'].apply(advanced_text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    modi promised minimum government maximum gover...\n",
       "1               talk nonsense continue drama vote modi\n",
       "2    say vote modi welcome bjp told rahul main camp...\n",
       "Name: lemmatized_content, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemmatized_content'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_tfidf():\n",
    "    \"\"\"Create an advanced TF-IDF vectorizer\"\"\"\n",
    "    return TfidfVectorizer(\n",
    "        min_df=5,  # Minimum document frequency\n",
    "        max_df=0.8,  # Maximum document frequency\n",
    "        ngram_range=(1, 2),  # Include both unigrams and bigrams\n",
    "        sublinear_tf=True,  # Apply sublinear scaling to term frequencies\n",
    "        strip_accents='unicode',\n",
    "        token_pattern=r'\\b\\w+\\b'  # Only match word characters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Train and evaluate multiple models using GridSearchCV\"\"\"\n",
    "    \n",
    "    # Create pipelines for different models\n",
    "    lr_pipeline = Pipeline([\n",
    "        ('tfidf', create_advanced_tfidf()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    rf_pipeline = Pipeline([\n",
    "        ('tfidf', create_advanced_tfidf()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    # Define parameter grids for GridSearchCV\n",
    "    lr_param_grid = {\n",
    "        'classifier__C': [0.1, 1.0, 10.0],\n",
    "        'classifier__class_weight': ['balanced', None],\n",
    "        'classifier__max_iter': [1000]\n",
    "    }\n",
    "    \n",
    "    rf_param_grid = {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [10, 20, None],\n",
    "        'classifier__class_weight': ['balanced', 'balanced_subsample']\n",
    "    }\n",
    "    \n",
    "    # Perform GridSearchCV for both models\n",
    "    lr_grid = GridSearchCV(lr_pipeline, lr_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    rf_grid = GridSearchCV(rf_pipeline, rf_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Train both models\n",
    "    print(\"Training Logistic Regression...\")\n",
    "    lr_grid.fit(X_train, y_train)\n",
    "    print(\"Training Random Forest...\")\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best models\n",
    "    best_lr = lr_grid.best_estimator_\n",
    "    best_rf = rf_grid.best_estimator_\n",
    "    \n",
    "    # Evaluate models\n",
    "    models = {\n",
    "        'Logistic Regression': best_lr,\n",
    "        'Random Forest': best_rf\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        \n",
    "        results[name] = {\n",
    "            'train_accuracy': accuracy_score(y_train, train_pred),\n",
    "            'test_accuracy': accuracy_score(y_test, test_pred),\n",
    "            'classification_report': classification_report(y_test, test_pred)\n",
    "        }\n",
    "    \n",
    "    return results, best_lr if lr_grid.best_score_ > rf_grid.best_score_ else best_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "      <th>lemmatized_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised âminimum government maxim...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>modi promised minimum government maximum gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk nonsense continue drama vote modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>say vote modi welcome bjp told rahul main camp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asking supporter prefix chowkidar name modi gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>answer among powerful world leader today trump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  target  \\\n",
       "0  when modi promised âminimum government maxim...      -1.0     2.0   \n",
       "1  talk all the nonsense and continue all the dra...       0.0     0.0   \n",
       "2  what did just say vote for modi  welcome bjp t...       1.0     1.0   \n",
       "3  asking his supporters prefix chowkidar their n...       1.0     1.0   \n",
       "4  answer who among these the most powerful world...       1.0     1.0   \n",
       "\n",
       "                                  lemmatized_content  \n",
       "0  modi promised minimum government maximum gover...  \n",
       "1             talk nonsense continue drama vote modi  \n",
       "2  say vote modi welcome bjp told rahul main camp...  \n",
       "3  asking supporter prefix chowkidar name modi gr...  \n",
       "4  answer among powerful world leader today trump...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemmatized_content'].values\n",
    "y = data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = data['lemmatized_content'].values\n",
    "y = data['target'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n",
      "Training Logistic Regression...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Training Random Forest...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Logistic Regression Results:\n",
      "Training Accuracy: 0.9728\n",
      "Test Accuracy: 0.8791\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.93      0.90     11042\n",
      "         1.0       0.90      0.89      0.89     14450\n",
      "         2.0       0.84      0.78      0.81      7102\n",
      "\n",
      "    accuracy                           0.88     32594\n",
      "   macro avg       0.87      0.87      0.87     32594\n",
      "weighted avg       0.88      0.88      0.88     32594\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Random Forest Results:\n",
      "Training Accuracy: 0.9994\n",
      "Test Accuracy: 0.8533\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89     11042\n",
      "         1.0       0.86      0.88      0.87     14450\n",
      "         2.0       0.85      0.67      0.75      7102\n",
      "\n",
      "    accuracy                           0.85     32594\n",
      "   macro avg       0.85      0.83      0.84     32594\n",
      "weighted avg       0.85      0.85      0.85     32594\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Train and evaluate models\n",
    "print(\"Training models...\")\n",
    "results, best_model = train_model(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Training Accuracy: {metrics['train_accuracy']:.4f}\")\n",
    "    print(f\"Test Accuracy: {metrics['test_accuracy']:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(metrics['classification_report'])    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'twitter_model_lemit.pkl'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved model\n",
    "\n",
    "loaded_model = pickle.load(open('twitter_model_lemit.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_test[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Negative tweet\n"
     ]
    }
   ],
   "source": [
    "prediction = (loaded_model.predict([X_new]))\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==0):\n",
    "    print('Negative tweet')\n",
    "else:\n",
    "    print('Positive tweet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis Model Evaluation Report\n",
    "\n",
    "## Overview\n",
    "This report presents a comprehensive evaluation of sentiment analysis models trained on a Twitter dataset, focusing on the performance of Logistic Regression and Random Forest classifiers.\n",
    "\n",
    "## Dataset Characteristics\n",
    "- **Total Samples**: 162,969\n",
    "- **Class Distribution**:\n",
    "  - Positive (1.0): 72,249 (44.3%)\n",
    "  - Negative (0.0): 55,211 (33.9%)\n",
    "  - Neutral (2.0): 35,509 (21.8%)\n",
    "\n",
    "## Model Performance Comparison\n",
    "\n",
    "| Metric | Logistic Regression | Random Forest |\n",
    "|--------|---------------------|---------------|\n",
    "| Training Accuracy | 0.9728 | 0.9994 |\n",
    "| Test Accuracy | 0.8791 | 0.8533 |\n",
    "\n",
    "### Detailed Performance Metrics\n",
    "\n",
    "#### Logistic Regression\n",
    "| Class | Precision | Recall | F1-Score |\n",
    "|-------|-----------|--------|----------|\n",
    "| Negative (0.0) | 0.88 | 0.93 | 0.90 |\n",
    "| Positive (1.0) | 0.90 | 0.89 | 0.89 |\n",
    "| Neutral (2.0) | 0.84 | 0.78 | 0.81 |\n",
    "\n",
    "#### Random Forest\n",
    "| Class | Precision | Recall | F1-Score |\n",
    "|-------|-----------|--------|----------|\n",
    "| Negative (0.0) | 0.85 | 0.94 | 0.89 |\n",
    "| Positive (1.0) | 0.86 | 0.88 | 0.87 |\n",
    "| Neutral (2.0) | 0.85 | 0.67 | 0.75 |\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "1. **Model Accuracy**\n",
    "   - Logistic Regression demonstrated slightly superior overall performance with a test accuracy of 87.91%\n",
    "   - Random Forest achieved a test accuracy of 85.33%\n",
    "\n",
    "2. **Model Complexity**\n",
    "   - Logistic Regression showed more balanced performance across sentiment classes\n",
    "   - Random Forest exhibited higher variance, particularly in neutral sentiment prediction\n",
    "\n",
    "3. **Training Efficiency**\n",
    "   - Logistic Regression required fewer grid search iterations (30 fits)\n",
    "   - Random Forest required more computational resources (60 fits)\n",
    "   - Both models showed signs of potential overfitting, with training accuracies significantly higher than test accuracies\n",
    "\n",
    "## Preprocessing Techniques\n",
    "- Advanced text preprocessing including:\n",
    "  - URL removal\n",
    "  - Mention and hashtag symbol removal\n",
    "  - Lowercasing\n",
    "  - Lemmatization\n",
    "  - Stopword removal\n",
    "- TF-IDF vectorization with:\n",
    "  - Unigram and bigram consideration\n",
    "  - Minimum document frequency of 5\n",
    "  - Maximum document frequency of 0.8\n",
    "\n",
    "## Recommendations\n",
    "1. Consider ensemble methods to improve neutral sentiment classification\n",
    "2. Explore additional feature engineering techniques\n",
    "3. Investigate potential class imbalance mitigation strategies\n",
    "\n",
    "## Conclusion\n",
    "The Logistic Regression model provides a robust solution for Twitter sentiment analysis, offering balanced performance across sentiment categories with high interpretability and computational efficiency.\n",
    "\n",
    "## Model Deployment\n",
    "- Best performing model (Logistic Regression) saved as 'twitter_model_lemit.pkl'\n",
    "- Ready for inference on new Twitter text data\n",
    "\n",
    "## Future Work\n",
    "- Experiment with deep learning approaches\n",
    "- Collect more diverse training data\n",
    "- Implement more advanced text representation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
